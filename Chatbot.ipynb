{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28636302-8d6d-4f57-b3b3-c8e044b84e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f996a4a-b981-4e61-8fbb-6fc818345f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load content from Resume Document \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"/data/SowmyaYellapragada-Resume.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3649669f-3f77-4002-a379-e590d85b1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Document into chunks for embedding and vector storage.\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 600, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2913756a-aaa6-4f71-8736-1943a268c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "model_1_embeddings = CohereEmbeddings(model = \"multilingual-22-12\")\n",
    "\n",
    "# Compute embeddings of the text splits\n",
    "db = Qdrant.from_documents(all_splits, model_1_embeddings, location=\":memory:\", collection_name=\"all_splits\", distance_func=\"Dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee37e94a-4360-41e9-94fc-fffb596cb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Cohere\n",
    "model_2_qa = RetrievalQA.from_chain_type(llm=Cohere(model=\"command-nightly\", temperature=0.9),\n",
    "                                         chain_type=\"stuff\",\n",
    "                                         retriever=db.as_retriever(),\n",
    "                                         return_source_documents=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6b20ed-b39d-4b23-872d-ba3a02218af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "           \"Whats the name of the resume holder\",\n",
    "           \"What is she experienced in?\", \n",
    "           \"Where did she work?\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b22f789-9fb2-4a2a-8b4b-2b435aacfd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whats the name of the resume holder\n",
      "The name of the resume holder is Sowmya Yellapragada. This can be found under the \"About Me\" section of the resume. \n",
      "\n",
      "\n",
      "What is she experienced in?\n",
      "Based on the provided information, Sowmya has experience as a software engineer with a focus on machine learning. Her experience includes designing and implementing machine learning infrastructure platforms, setting up data pipelines, developing microservices, and leading teams. She also has experience with specific software systems, languages, and tools such as ArgoCD, Concourse, Golang, and Git, among others.  Her record of designing and implementing an ML infrastructure platform and her patent in predicting travel time show her expertise and contribution to the field.  It might be helpful to clarify any specific area of experience you are interested in to give a more detailed answer.  I don't know is an acceptable answer and might be the best approach given the general nature of your question.   To gain a thorough understanding of her experience, review the provided resume.\n",
      "\n",
      "\n",
      "Where did she work?\n",
      "The candidate worked remotely for GoPuff as a Senior Machine Learning Engineer, and previously held roles at Daimler Mobility Services GmbH, Birla Institute of Technology and Sciences, and Georgia Institute of Technology. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    answer = model_2_qa({\"query\": question})\n",
    "    print(answer[\"query\"])\n",
    "    print(answer[\"result\"])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c6d012-973b-4a4f-807f-e9056a84cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Cohere\n",
    "llm = Cohere(model = \"command-nightly\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f8938b-2190-402e-86d9-ec8e869e018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "#Setup Chat History\n",
    "#The chat_history variable keeps track of the conversation history, storing the user queries #and the chatbot's responses\n",
    "#This allows the chatbot to maintain context and provide relevant answers based on past interactions.\n",
    "chat_history = []\n",
    "model_3_qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    memory = ConversationSummaryMemory(llm = llm, memory_key='chat_history', input_key='question', output_key= 'answer', return_messages=True),\n",
    "    retriever = db.as_retriever(),\n",
    "    return_source_documents=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1aebfa-532c-4cef-aff1-f9f41587a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QandA(question):\n",
    "    global chat_history\n",
    "    result = model_3_qa({\"question\": question, \"chat_history\": chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    return result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb55cb7e-4e94-485b-893a-f2f90e93f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:8889\n",
      "Running on public URL: https://81c19218a6ba798172.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://81c19218a6ba798172.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n",
      "Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n",
      "Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n",
      "Retrying langchain_community.llms.cohere.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised TooManyRequestsError: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 5 API calls / minute. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}.\n"
     ]
    }
   ],
   "source": [
    "#DocumentQA Interface\n",
    "DocQABotUI = gr.Interface(\n",
    "    fn=QandA,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Chatbot\",\n",
    "    description=\"Document QA\"\n",
    ")\n",
    "#Launching the DocQABot\n",
    "DocQABotUI.launch(share=True,server_port=8889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9f967-9c8a-4f4c-bbda-6ce713835c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
